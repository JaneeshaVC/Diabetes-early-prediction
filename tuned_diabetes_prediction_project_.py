# -*- coding: utf-8 -*-
"""Tuned Diabetes prediction project .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_ZNElqw3BQ15Vzg5JLi_qMVfI-vxBsfu
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import sklearn as sk
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

#data loading
ori_data=pd.read_csv("/content/diabetes_binary_health_indicators_BRFSS2015.csv")
ori_data=ori_data.drop(['AnyHealthcare','NoDocbcCost','GenHlth','PhysHlth','Education','Income'],axis=1)
#Pre processing and EDA
rows,cols=ori_data.shape
print("number of records:",rows)
print("number of features:",cols)
#printing the first 5 records
ori_data.head()
#printing the last 5 records
ori_data.tail()

#printing the data types
ori_data.dtypes
ori_data.info
#converting the data types from float to integer
ori_data["Diabetes_binary"] = ori_data["Diabetes_binary"].astype(int)
ori_data["HighBP"] = ori_data["HighBP"].astype(int)
ori_data["HighChol"] = ori_data["HighChol"].astype(int)
ori_data["CholCheck"] = ori_data["CholCheck"].astype(int)
ori_data["BMI"] = ori_data["BMI"].astype(int)
ori_data["Smoker"] = ori_data["Smoker"].astype(int)
ori_data["Stroke"] = ori_data["Stroke"].astype(int)
ori_data["HeartDiseaseorAttack"] = ori_data["HeartDiseaseorAttack"].astype(int)
ori_data["PhysActivity"] = ori_data["PhysActivity"].astype(int)
ori_data["Fruits"] = ori_data["Fruits"].astype(int)
ori_data["Veggies"] = ori_data["Veggies"].astype(int)
ori_data["HvyAlcoholConsump"] = ori_data["HvyAlcoholConsump"].astype(int)
ori_data["MentHlth"] = ori_data["MentHlth"].astype(int)
ori_data["DiffWalk"] = ori_data["DiffWalk"].astype(int)
ori_data["Sex"] = ori_data["Sex"].astype(int)
ori_data["Age"] = ori_data["Age"].astype(int)
#checking the data type after conversion
print(ori_data.info)
#printing the summary statistics
stat_info=ori_data.describe()
print(stat_info)
#printing the null value sum
null_sum=ori_data.isnull().sum()
print(null_sum)
if null_sum.any():
  null_percent=(100*null_sum)/len(ori_data)
  print(null_percent)
else:
  print("No null value found in the dataset!")
#null value cheking and fill na method if needed
duplicate_sum=ori_data.duplicated().sum()
print("the number of duplicates in the dataser=t:",duplicate_sum)
ori_data.drop_duplicates(inplace=True)
#checking the number of records after removing duplicates
rows,cols=ori_data.shape
print("Number of records after dropping duplicates:",rows)
#creating box polts to detect outliers
num_rows,num_cols=3,1
fig,axes=plt.subplots(num_rows,num_cols,figsize=(15,30))
axes=axes.flatten()
for i,column in enumerate(['BMI','MentHlth','Age']):
  sns.boxplot(data= ori_data,x=column,ax=axes[i])
  axes[i].set_title(f'Boxplot for {column}')
for j in range(len(ori_data.columns),len(axes)):
  fig.delaxes(axes[j])
plt.tight_layout()
plt.show()

#visulaize the boxplots and detect the collumns with outliers, use the code only to remove the outliers.
# Define columns to check for outliers
outlier_columns = ['BMI']

# Create a copy of the original data to avoid modifying it directly
data_cleaned = ori_data.copy()

# Loop through each column to calculate IQR and remove outliers
for col in outlier_columns:
    # Calculate Q1 (25th percentile) and Q3 (75th percentile)
    Q1 = data_cleaned[col].quantile(0.25)
    Q3 = data_cleaned[col].quantile(0.75)

    # Calculate IQR (Interquartile Range)
    IQR = Q3 - Q1

    # Define the outlier thresholds
    LB = Q1 - 1.5 * IQR
    UB= Q3 + 1.5 * IQR

    # Remove outliers for this column
    data_cleaned = data_cleaned[(data_cleaned[col] >= LB) & (data_cleaned[col] <= UB)]

# Print the cleaned dataset without outliers
print(data_cleaned.head())
#creating box polts to detect outliers
num_rows,num_cols=1,1
fig,axes=plt.subplots(num_rows,num_cols,figsize=(15,30))
for i,column in enumerate(outlier_columns):
  sns.boxplot(data= data_cleaned,x=column,ax=axes)
  axes.set_title(f'Boxplot for {column}')
plt.tight_layout()
plt.show()

num_rows,num_cols=3,1
fig,axes=plt.subplots(num_rows,num_cols,figsize=(15,30))
axes=axes.flatten()
for i,column in enumerate(['BMI','MentHlth','Age']):
  sns.boxplot(data= data_cleaned,x=column,ax=axes[i])
  axes[i].set_title(f'Boxplot for {column}')
for j in range(len(data_cleaned.columns),len(axes)):
  fig.delaxes(axes[j])
plt.tight_layout()
plt.show()

#renaming the diabetes binary column as "outcome"
data_cleaned.rename(columns={"Diabetes_binary": "Outcome"},inplace=True)

#checking the unique values in each column
unique_values = {}
for col in data_cleaned.columns:
    unique_values[col] = data_cleaned[col].value_counts().shape[0]

pd.DataFrame(unique_values, index=['unique value count']).transpose()

#getting the values counts for each occurence
def v_counts(dataframe):
    for col in dataframe.columns:
        print(f"Column: {col}")
        print(dataframe[col].value_counts().reset_index(name="Count").rename(columns={"index": col}))
        print("_____________________________________________________________________________")
v_counts(data_cleaned)

#making a copy of the cleaned data set
cleaned_copy=data_cleaned.copy()
#adding columns with stating the features
#Outcome
cleaned_copy.Outcome[cleaned_copy['Outcome'] == 0] = 'No Diabetes'
cleaned_copy.Outcome[cleaned_copy['Outcome'] == 1] = 'Diabetes'

#age
cleaned_copy.Age[cleaned_copy['Age'] == 1] = '18 to 24'
cleaned_copy.Age[cleaned_copy['Age'] == 2] = '25 to 29'
cleaned_copy.Age[cleaned_copy['Age'] == 3] = '30 to 34'
cleaned_copy.Age[cleaned_copy['Age'] == 4] = '35 to 39'
cleaned_copy.Age[cleaned_copy['Age'] == 5] = '40 to 44'
cleaned_copy.Age[cleaned_copy['Age'] == 6] = '45 to 49'
cleaned_copy.Age[cleaned_copy['Age'] == 7] = '50 to 54'
cleaned_copy.Age[cleaned_copy['Age'] == 8] = '55 to 59'
cleaned_copy.Age[cleaned_copy['Age'] == 9] = '60 to 64'
cleaned_copy.Age[cleaned_copy['Age'] == 10] = '65 to 69'
cleaned_copy.Age[cleaned_copy['Age'] == 11] = '70 to 74'
cleaned_copy.Age[cleaned_copy['Age'] == 12] = '75 to 79'
cleaned_copy.Age[cleaned_copy['Age'] == 13] = '80 or older'

#High BP occurence
cleaned_copy.HighBP[cleaned_copy['HighBP'] == 0] = 'No High'
cleaned_copy.HighBP[cleaned_copy['HighBP'] == 1] = 'High BP'

#High cholestrol occurence
cleaned_copy.HighChol[cleaned_copy['HighChol'] == 0] = 'No High Cholesterol'
cleaned_copy.HighChol[cleaned_copy['HighChol'] == 1] = 'High Cholesterol'

#cholesterol check occurence for 5 years
cleaned_copy.CholCheck[cleaned_copy['CholCheck'] == 0] = 'No Cholesterol Check in 5 Years'
cleaned_copy.CholCheck[cleaned_copy['CholCheck'] == 1] = 'Cholesterol Check in 5 Years'

#smoker or not
cleaned_copy.Smoker[cleaned_copy['Smoker'] == 0] = 'No'
cleaned_copy.Smoker[cleaned_copy['Smoker'] == 1] = 'Yes'

#Stroke occured or not
cleaned_copy.Stroke[cleaned_copy['Stroke'] == 0] = 'No'
cleaned_copy.Stroke[cleaned_copy['Stroke'] == 1] = 'Yes'

#heart attack occurence
cleaned_copy.HeartDiseaseorAttack[cleaned_copy['HeartDiseaseorAttack'] == 0] = 'No'
cleaned_copy.HeartDiseaseorAttack[cleaned_copy['HeartDiseaseorAttack'] == 1] = 'Yes'

#Excerising or not
cleaned_copy.PhysActivity[cleaned_copy['PhysActivity'] == 0] = 'No'
cleaned_copy.PhysActivity[cleaned_copy['PhysActivity'] == 1] = 'Yes'

#consuming frutis or not
cleaned_copy.Fruits[cleaned_copy['Fruits'] == 0] = 'No'
cleaned_copy.Fruits[cleaned_copy['Fruits'] == 1] = 'Yes'

#consuming vegetables or not
cleaned_copy.Veggies[cleaned_copy['Veggies'] == 0] = 'No'
cleaned_copy.Veggies[cleaned_copy['Veggies'] == 1] = 'Yes'

#a heavy alcohol consumer or not
cleaned_copy.HvyAlcoholConsump[cleaned_copy['HvyAlcoholConsump'] == 0] = 'No'
cleaned_copy.HvyAlcoholConsump[cleaned_copy['HvyAlcoholConsump'] == 1] = 'Yes'

#
cleaned_copy.DiffWalk[cleaned_copy['DiffWalk'] == 0] = 'No'
cleaned_copy.DiffWalk[cleaned_copy['DiffWalk'] == 1] = 'Yes'

#sex of the individual
cleaned_copy.Sex[cleaned_copy['Sex'] == 0] = 'Female'
cleaned_copy.Sex[cleaned_copy['Sex'] == 1] = 'Male'

cleaned_copy.head()

#EDA
#correlation check by using heatmaps
plt.figure(figsize=(30,10))
sns.heatmap(data_cleaned.corr(),annot=True,cmap='YlOrRd')
plt.title("Correlation of the features")

#correlating features with the outcome -
correlations=data_cleaned.corr()
#linearly correlating features in a threshold greater than 0.2
corr_features=correlations.index[abs(correlations["Outcome"])>=0.2]
#features which doesnt show a correlation in the 0.2 threshold
not_corr_features=correlations.index[abs(correlations["Outcome"])<0.2]
print("Linearly correlating features:", corr_features)
print("Doesn't show linear relationships:", not_corr_features)

data_cleaned.hist(figsize=(15,15))
plt.show()

#counting the values of non diabetic patients and diabetic patients
Outcome=cleaned_copy["Outcome"].value_counts()
print(Outcome)
#plotting the above result as a bar chart and pie chart
#count plot
fig1,axes=plt.subplots(1,2,figsize=(20,15))
sns.countplot(x=cleaned_copy['Outcome'],ax=axes[0],palette="pastel")
axes[0].set_title("DIABETES COUNT PLOT")
axes[0].set_xlabel("Outcome")
axes[0].set_ylabel("Count")
#pie chart
labels=["Non Diabetic", "Diabetic"]
axes[1].pie(cleaned_copy["Outcome"].value_counts(),labels=labels,autopct='%.2f%%',startangle=90,colors=['skyblue','salmon'])
axes[1].set_title("DIABETIC COUNTS IN PERCENTAGE")
plt.tight_layout()
plt.show()

#visualization of the binary features with the target variable
cols=['HighBP','HighChol','CholCheck','Smoker','Stroke','HeartDiseaseorAttack','PhysActivity','Fruits','Veggies','HvyAlcoholConsump','DiffWalk','Sex']
def creating_plots(cleaned_copy,x_column):
  df=cleaned_copy.groupby([x_column,"Outcome"]).size().reset_index().pivot(columns="Outcome",index=x_column,values=0)
  return df

fig,ax=plt.subplots(4,3,figsize=(20,20))
axe=ax.ravel()
c=len(cols)
for i in range(c):
  creating_plots(cleaned_copy,cols[i]).plot(kind='bar',stacked=True,ax=axe[i])
  axe[i].set_xlabel(cols[i])
fig.show()

#relationship between the target variable and the features
#Age
sns.boxplot(x="Outcome",y="Age",data=data_cleaned,palette="pastel")
plt.title("AGE vs DIABETIC CONDITION")
plt.show()

#BMI
ax=sns.displot(data=data_cleaned,x="BMI",hue="Outcome",kind="kde",fill=True)
legend=ax.legend
legend.get_texts()[0].set_text("No Diabetes")
legend.get_texts()[1].set_text("Diabetic")
plt.title("BMI vs DIABETIC CONDITION")
plt.tight_layout()
plt.show()

#Mental Health
ax=sns.catplot(data=data_cleaned,kind="bar",x="Outcome",y="MentHlth",hue="Outcome")
egend=ax.legend
legend.get_texts()[0].set_text("No Diabetes")
legend.get_texts()[1].set_text("Diabetic")
plt.title("MENTAL HEALTH vs DIABETIC CONDITION")
plt.show()

sns.boxplot(x="Outcome",y="MentHlth",data=data_cleaned,palette="pastel")
plt.title("MENTAL HEALTH vs DIABETIC CONDITION")
plt.show()

ax=sns.displot(data=data_cleaned,x="MentHlth",hue="Outcome",kind="kde",fill=True)
legend=ax.legend
legend.get_texts()[0].set_text("No Diabetes")
legend.get_texts()[1].set_text("Diabetic")
plt.title("MENTAL HEALTH vs DIABETIC CONDITION")
plt.tight_layout()
plt.show()

#Feature selection
data_cleaned.drop("Outcome",axis=1).corrwith(data_cleaned.Outcome).plot(kind='bar',grid=True,figsize=(20,15),title="Correlation of the features with the outcome",color="Blue");

#spearman correlation for the non linear features
spear_corr=data_cleaned.corr(method="spearman")
print(spear_corr["Outcome"].sort_values(ascending=False))
corr_features=spear_corr.index[abs(spear_corr["Outcome"])>=0.15]
print("the features greater >=0.2 threshold are:",corr_features)
plt.figure(figsize=(20,15))
sns.heatmap(spear_corr,annot=True,cmap="rocket_r",fmt=".2f")
plt.title("Spearman Correlation Heatmap")
plt.show()

#VIF test
from statsmodels.stats.outliers_influence import variance_inflation_factor
features=data_cleaned.drop(columns=["Outcome"])
vif=pd.DataFrame()
vif["Features"]=features.columns
vif["VIF"]=[variance_inflation_factor(features.values,i)for i in range(features.shape[1])]
print(vif)

#Cholcheck, BMI VIF was greater than 10, so running the test again by removing them
features2=data_cleaned.drop(columns=["CholCheck","BMI","Outcome"])
vif=pd.DataFrame()
vif["Features"]=features2.columns
vif["VIF"]=[variance_inflation_factor(features2.values,i)for i in range(features2.shape[1])]
print(vif)
vif_good=vif[vif["VIF"]<10]
features=vif_good["Features"].tolist()
print("Features with less multicollinearity are:")
print(features)

#chi square test to evaluate the siginificance
from scipy.stats import chi2_contingency
cat_var=data_cleaned.drop(columns=["Outcome"])
chi_sqr_results={}
for var in cat_var:
  contingency_table=pd.crosstab(data_cleaned[var],data_cleaned["Outcome"])
  chi2,p_value,dof,expected=chi2_contingency(contingency_table)
  chi_sqr_results[var]=p_value

chi_sqr_df=pd.DataFrame(chi_sqr_results.items(),columns=["Features","p-value"])
chi_sqr_df=chi_sqr_df.sort_values(by="p-value")
print(chi_sqr_df)

chi_good=chi_sqr_df[chi_sqr_df["p-value"]<0.05]
features=chi_good["Features"].tolist()
print("Features with high significance are:")
print(features)

#selected features based on the results priortizing the chi square and VIF
selected_features=data_cleaned.drop(columns=["CholCheck","BMI"])

#data splitting
#x- predicting features
X=selected_features.drop(columns=["Outcome"])
#y-dep.variable
y=data_cleaned["Outcome"]

#data splitting for training and testing (80/20)
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)

#checking the class imbalance - to check what to use between SMOTE or near miss
print(y.value_counts(normalize=True))

#uninstalled as an error arose
!pip uninstall -y scikit-learn
!pip uninstall -y imbalanced-learn

#installed again for the analysis
!pip install scikit-learn==1.3.2
!pip install imbalanced-learn==0.9.1

#class balancing
#using SMOTE as its not an extreme imbalance scenario
from collections import Counter
from imblearn.over_sampling import SMOTE
#random sample= 0 ensures that the same synthetic samples are produced.
smote=SMOTE(random_state=0)
X_train_b,y_train_b=smote.fit_resample(X_train,y_train)
print("Before SMOTE:",Counter(y_train))
print("After SMOTE:",Counter(y_train_b))

sns.histplot(data_cleaned["Age"], kde=True)
plt.show()



#feature scaling - normalization
#feature scaling is only performed to "age" as it is obeying an ordinal relationship
#rest of the features obeys a binary classification
from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
#making a copy of the train balanced
X_train_b_norm = X_train_b.copy()
#making a copy of the test
X_test_norm = X_test.copy()
#doing the normalization only for age
X_train_b_norm["Age"]=scaler.fit_transform(X_train_b[["Age"]])
X_test_norm["Age"]=scaler.transform(X_test[["Age"]])

#RFE done to get the plot
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFE
model=LogisticRegression(max_iter=500)

rfe = RFE(estimator=model, n_features_to_select=5)
rfe.fit(X_train_b_norm, y_train_b)

ranking = rfe.ranking_

for feature, rank in zip(X_train_b_norm.columns, ranking):
    print(f"Feature: {feature}, Rank: {rank}")

coefficients = model.fit(X_train_b_norm, y_train_b).coef_[0]


plt.figure(figsize=(10,6))
plt.barh(X_train_b_norm.columns, coefficients)
plt.xlabel('Feature Importance')
plt.title('Feature Importance Plot')
plt.show()


sel_features = X_train_b_norm.columns[rfe.support_]
print("Selected features based on RFE:", sel_features)

#RFE to get the features
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFE
log_reg=LogisticRegression(max_iter=500)
rfe=RFE(log_reg,n_features_to_select=5)
rfe=rfe.fit(X_train_b_norm,y_train_b)
sel_features=X_train_b_norm.columns[rfe.support_]
print("Selected features:",sel_features)
print("Number of selected features:",len(sel_features))
X_train_selected = X_train_b_norm[sel_features]
X_test_selected = X_test_norm[sel_features]

#Modelling
#Logisitc Regression
from sklearn.linear_model import LogisticRegression
from sklearn.feature_selection import RFE
log_reg=LogisticRegression(C=10,penalty="l2",solver="liblinear",max_iter=1000)
log_reg.fit(X_train_selected,y_train_b)

#predictions - LR
from sklearn.metrics import (accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report,roc_curve,roc_auc_score)
#Training score
train_pred=log_reg.predict(X_train_selected)
train_score=accuracy_score(y_train_b,train_pred)
print("The training score:",train_score)
#Testing score
test_pred=log_reg.predict(X_test_selected)
test_score=accuracy_score(y_test,test_pred)
print("The testing accuracy:",test_score)
#classification report
print("The classification report:")
print(classification_report(y_test,test_pred))
#ROC-AUC score
y_pred_prob=log_reg.predict_proba(X_test_selected)[:,1]
roc_auc=roc_auc_score(y_test,y_pred_prob)
print("The ROC AUC score:",roc_auc)
#confusion matrix
conf_matrix=confusion_matrix(y_test,test_pred)
conf_norm=conf_matrix.astype('float')/conf_matrix.sum(axis=1,keepdims=True)
print("The confusion matrix:")
plt.figure(figsize=(5,5))
sns.heatmap(conf_norm*100,annot=True,fmt=".2f",xticklabels=[0,1],yticklabels=[0,1])
plt.xlabel("Predicted")
plt.ylabel("True values")
plt.title("Confusion matrix plot")
plt.show()

#Decision Tree
from sklearn.tree import DecisionTreeClassifier
decision_tree=DecisionTreeClassifier(max_depth=4, min_samples_leaf=30, class_weight='balanced',random_state=50)
decision_tree.fit(X_train_selected,y_train_b)

#Training score
train_pred=decision_tree.predict(X_train_selected)
train_score=accuracy_score(y_train_b,train_pred)
print("The training score:",train_score)
#Testing score
test_pred=decision_tree.predict(X_test_selected)
test_score=accuracy_score(y_test,test_pred)
print("The testing accuracy:",test_score)
#classification report
print("The classification report:")
print(classification_report(y_test,test_pred))
#ROC-AUC score
y_pred_prob=decision_tree.predict_proba(X_test_selected)[:,1]
roc_auc=roc_auc_score(y_test,y_pred_prob)
print("The ROC AUC score:",roc_auc)
#confusion matrix
conf_matrix=confusion_matrix(y_test,test_pred)
conf_norm=conf_matrix.astype('float')/conf_matrix.sum(axis=1,keepdims=True)
print("The confusion matrix:")
plt.figure(figsize=(5,5))
sns.heatmap(conf_norm*100,annot=True,fmt=".2f",xticklabels=[0,1],yticklabels=[0,1])
plt.xlabel("Predicted")
plt.ylabel("True values")
plt.title("Confusion matrix plot")
plt.show()

#Random Forest
from sklearn.ensemble import RandomForestClassifier
rand_class=RandomForestClassifier(n_estimators=400,min_samples_leaf=5, random_state=50)
rand_class.fit(X_train_selected,y_train_b)

#Training score
train_pred=rand_class.predict(X_train_selected)
train_score=accuracy_score(y_train_b,train_pred)
print("The training score:",train_score)
#Testing score
test_pred=rand_class.predict(X_test_selected)
test_score=accuracy_score(y_test,test_pred)
print("The testing accuracy:",test_score)
#classification report
print("The classification report:")
print(classification_report(y_test,test_pred))
#ROC-AUC score
y_pred_prob=rand_class.predict_proba(X_test_selected)[:,1]
roc_auc=roc_auc_score(y_test,y_pred_prob)
print("The ROC AUC score:",roc_auc)
#confusion matrix
conf_matrix=confusion_matrix(y_test,test_pred)
conf_norm=conf_matrix.astype('float')/conf_matrix.sum(axis=1,keepdims=True)
print("The confusion matrix:")
plt.figure(figsize=(5,5))
sns.heatmap(conf_norm*100,annot=True,fmt=".2f",xticklabels=[0,1],yticklabels=[0,1])
plt.xlabel("Predicted")
plt.ylabel("True values")
plt.title("Confusion matrix plot")
plt.show()

#KNN
from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier(weights='distance',metric='manhattan', n_neighbors=5)
knn.fit(X_train_selected,y_train_b)

#Training score
train_pred=knn.predict(X_train_selected)
train_score=accuracy_score(y_train_b,train_pred)
print("The training score:",train_score)
#Testing score
test_pred=knn.predict(X_test_selected)
test_score=accuracy_score(y_test,test_pred)
print("The testing accuracy:",test_score)
#classification report
print("The classification report:")
print(classification_report(y_test,test_pred))
#ROC-AUC score
y_pred_prob=knn.predict_proba(X_test_selected)[:,1]
roc_auc=roc_auc_score(y_test,y_pred_prob)
print("The ROC AUC score:",roc_auc)
#confusion matrix
conf_matrix=confusion_matrix(y_test,test_pred)
conf_norm=conf_matrix.astype('float')/conf_matrix.sum(axis=1,keepdims=True)
print("The confusion matrix:")
plt.figure(figsize=(5,5))
sns.heatmap(conf_norm*100,annot=True,fmt=".2f",xticklabels=[0,1],yticklabels=[0,1])
plt.xlabel("Predicted")
plt.ylabel("True values")
plt.title("Confusion matrix plot")
plt.show()

#NB
from sklearn.naive_bayes import BernoulliNB
naive_bayes = BernoulliNB(alpha=0.1, binarize=0.3, fit_prior=False)
naive_bayes.fit(X_train_selected, y_train_b)

#Training score
train_pred=naive_bayes.predict(X_train_selected)
train_score=accuracy_score(y_train_b,train_pred)
print("The training score:",train_score)
#Testing score
test_pred=naive_bayes.predict(X_test_selected)
test_score=accuracy_score(y_test,test_pred)
print("The testing accuracy:",test_score)
#classification report
print("The classification report:")
print(classification_report(y_test,test_pred))
#ROC-AUC score
y_pred_prob=naive_bayes.predict_proba(X_test_selected)[:,1]
roc_auc=roc_auc_score(y_test,y_pred_prob)
print("The ROC AUC score:",roc_auc)
#confusion matrix
conf_matrix=confusion_matrix(y_test,test_pred)
conf_norm=conf_matrix.astype('float')/conf_matrix.sum(axis=1,keepdims=True)
print("The confusion matrix:")
plt.figure(figsize=(5,5))
sns.heatmap(conf_norm*100,annot=True,fmt=".2f",xticklabels=[0,1],yticklabels=[0,1])
plt.xlabel("Predicted")
plt.ylabel("True values")
plt.title("Confusion matrix plot")
plt.show()

#cross validation
from sklearn.model_selection import cross_val_score, KFold
kf = KFold(n_splits=5, shuffle=True, random_state=50)

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(min_samples_leaf=5, n_estimators=400, random_state=50)

# Perform 5-fold cross-validation
accuracy = cross_val_score(rf_model, X_train_selected, y_train_b, cv=kf, scoring='accuracy')
precision = cross_val_score(rf_model, X_train_selected, y_train_b, cv=kf, scoring='precision')
recall = cross_val_score(rf_model, X_train_selected, y_train_b, cv=kf, scoring='recall')
f1 = cross_val_score(rf_model, X_train_selected, y_train_b, cv=kf, scoring='f1')
roc_auc = cross_val_score(rf_model, X_train_selected, y_train_b, cv=kf, scoring='roc_auc')

print(f"Random Forest - 10-Fold Cross-Validation Results:")
print(f"Mean Accuracy: {np.mean(accuracy):.4f}")
print(f"Mean Precision: {np.mean(precision):.4f}")
print(f"Mean Recall: {np.mean(recall):.4f}")
print(f"Mean F1 Score: {np.mean(f1):.4f}")
print(f"Mean ROC AUC: {np.mean(roc_auc):.4f}")

def cross_validate_model(model, X, y, cv=5):
    accuracy = cross_val_score(model, X, y, cv=cv, scoring='accuracy')
    precision = cross_val_score(model, X, y, cv=cv, scoring='precision')
    recall = cross_val_score(model, X, y, cv=cv, scoring='recall')
    f1 = cross_val_score(model, X, y, cv=cv, scoring='f1')
    roc_auc = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')

    print(f"Model: {model.__class__.__name__}")
    print(f"Mean Accuracy: {np.mean(accuracy):.4f}")
    print(f"Mean Precision: {np.mean(precision):.4f}")
    print(f"Mean Recall: {np.mean(recall):.4f}")
    print(f"Mean F1 Score: {np.mean(f1):.4f}")
    print(f"Mean ROC AUC: {np.mean(roc_auc):.4f}")
    print("-" * 40)

models = [log_reg, decision_tree, rand_class, knn, naive_bayes]  # Replace with your trained model objects

for model in models:
    cross_validate_model(model, X_train_selected, y_train_b)

